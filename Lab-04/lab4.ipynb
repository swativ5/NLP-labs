{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51eac49",
   "metadata": {},
   "source": [
    "1. Load the dataset into a Pandas DataFrame and extract the text and label columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa057c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load the given CSV file containing text and label columns into a Pandas DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# First column contains review, second column contains the label(Positive, negative, neutral).\n",
    "\n",
    "print(\"Load the given CSV file containing text and label columns into a Pandas DataFrame.\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# https://www.kaggle.com/code/akanksha10/sentiment-analysis-dataset/input\n",
    "df = pd.read_csv('test.csv', encoding='latin1')\n",
    " \n",
    "df = df.drop(columns=[col for col in df.columns if col not in ['text', 'sentiment']])\n",
    "\n",
    "df = df.dropna()\n",
    "df = df.drop(df.index[100:])\n",
    "df = df.rename(columns={'sentiment':'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a980397",
   "metadata": {},
   "source": [
    "2. Reuse the preprocessed text obtained in Lab-3 (after tokenization, case folding, stop-word removal, and joining tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef45fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed for 100 documents\n",
      "Original text: Last session of the day  http://twitpic.com/67ezh\n",
      "Tokens: ['last', 'session', 'of', 'the', 'day', 'http']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "df['tokens'] = df['text'].apply(lambda x: word_tokenize(str(x).lower()))\n",
    "df['tokens'] = df['tokens'].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "print(f\"Tokenization completed for {len(df)} documents\")\n",
    "print(f\"Original text: {df['text'].iloc[0]}\")\n",
    "print(f\"Tokens: {df['tokens'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc0f81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - Document 1:\n",
      "Original text: Last session of the day  http://twitpic.com/67ezh\n",
      "Tokens: ['last', 'session', 'of', 'the', 'day', 'http']\n",
      "\n",
      "Example - Document 2:\n",
      "Original text:  Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).\n",
      "Tokens: ['shanghai', 'is', 'also', 'really', 'exciting', 'precisely', 'skyscrapers', 'galore', 'good', 'tweeps', 'in', 'china', 'sh', 'bj']\n",
      "\n",
      "Example - Document 3:\n",
      "Original text: Recession hit Veronique Branquinho, she has to quit her company, such a shame!\n",
      "Tokens: ['recession', 'hit', 'veronique', 'branquinho', 'she', 'has', 'to', 'quit', 'her', 'company', 'such', 'a', 'shame']\n",
      "\n",
      "NLTK Tokenization ensures that the tokens are already lowercase\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"Example - Document {i+1}:\")\n",
    "    print(f\"Original text: {df['text'].iloc[i]}\")\n",
    "    print(f\"Tokens: {df['tokens'].iloc[i]}\\n\")\n",
    "print(\"NLTK Tokenization ensures that the tokens are already lowercase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ef66d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     label  \\\n",
      "0  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
      "1   Shanghai is also really exciting (precisely -...  positive   \n",
      "2  Recession hit Veronique Branquinho, she has to...  negative   \n",
      "3                                        happy bday!  positive   \n",
      "4             http://twitpic.com/4w75p - I like it!!  positive   \n",
      "\n",
      "                                              tokens  \\\n",
      "0                [last, session, of, the, day, http]   \n",
      "1  [shanghai, is, also, really, exciting, precise...   \n",
      "2  [recession, hit, veronique, branquinho, she, h...   \n",
      "3                                      [happy, bday]   \n",
      "4                                [http, i, like, it]   \n",
      "\n",
      "                            tokens_without_stopwords  \n",
      "0                         [last, session, day, http]  \n",
      "1  [shanghai, also, really, exciting, precisely, ...  \n",
      "2  [recession, hit, veronique, branquinho, quit, ...  \n",
      "3                                      [happy, bday]  \n",
      "4                                       [http, like]  \n",
      "Stop-word removal completed.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Load English stop-words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "df['tokens_without_stopwords'] = df['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "print(df.head())\n",
    "print(f\"Stop-word removal completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9f902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text     label  \\\n",
      "0  Last session of the day  http://twitpic.com/67ezh   neutral   \n",
      "1   Shanghai is also really exciting (precisely -...  positive   \n",
      "2  Recession hit Veronique Branquinho, she has to...  negative   \n",
      "3                                        happy bday!  positive   \n",
      "4             http://twitpic.com/4w75p - I like it!!  positive   \n",
      "\n",
      "                                              tokens  \\\n",
      "0                [last, session, of, the, day, http]   \n",
      "1  [shanghai, is, also, really, exciting, precise...   \n",
      "2  [recession, hit, veronique, branquinho, she, h...   \n",
      "3                                      [happy, bday]   \n",
      "4                                [http, i, like, it]   \n",
      "\n",
      "                            tokens_without_stopwords  \\\n",
      "0                         [last, session, day, http]   \n",
      "1  [shanghai, also, really, exciting, precisely, ...   \n",
      "2  [recession, hit, veronique, branquinho, quit, ...   \n",
      "3                                      [happy, bday]   \n",
      "4                                       [http, like]   \n",
      "\n",
      "                                   lemmatized_tokens  \n",
      "0                         [last, session, day, http]  \n",
      "1  [shanghai, also, really, exciting, precisely, ...  \n",
      "2  [recession, hit, veronique, branquinho, quit, ...  \n",
      "3                                      [happy, bday]  \n",
      "4                                       [http, like]  \n",
      "Lemmatization completed.\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['lemmatized_tokens'] = df['tokens_without_stopwords'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "print(df.head())\n",
    "print(f\"Lemmatization completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d84c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Last session of the day  http://twitpic.com/67ezh   \n",
      "1   Shanghai is also really exciting (precisely -...   \n",
      "2  Recession hit Veronique Branquinho, she has to...   \n",
      "3                                        happy bday!   \n",
      "4             http://twitpic.com/4w75p - I like it!!   \n",
      "\n",
      "                                        final_tokens  \n",
      "0                              last session day http  \n",
      "1  shanghai also really exciting precisely skyscr...  \n",
      "2  recession hit veronique branquinho quit compan...  \n",
      "3                                         happy bday  \n",
      "4                                          http like  \n"
     ]
    }
   ],
   "source": [
    "df['final_tokens'] = df['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n",
    "print(df[['text', 'final_tokens']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3fcbf",
   "metadata": {},
   "source": [
    "3. Load the previously constructed Bag-of-Words document–term matrix from Lab-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "971fd22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lemmatization-based Vocabulary size: 453\n",
      "Sample BoW tokens: ['underwire', 'cant', 'realise', 'day', 'split', 'coding', 'much', 'sign', 'let', 'guy', 'hey', 'bore', 'breaky', 'salvation', 'jimmy', 'snicker', 'haaaw', 'come', 'able', 'bike', 'almost', 'hole', 'link', 'known', 'dawson', 'shop', 'uk', 'lie', 'like', 'ramen']\n"
     ]
    }
   ],
   "source": [
    "token_population_lemmatized = [ltoken for ltokens in df['lemmatized_tokens'] for ltoken in ltokens]\n",
    "\n",
    "# Create unique vocabulary\n",
    "vocab_lemma = list(set(token_population_lemmatized))\n",
    "\n",
    "print(f\"\\nLemmatization-based Vocabulary size: {len(vocab_lemma)}\")\n",
    "print(f\"Sample BoW tokens: {vocab_lemma[:30]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fab8de23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM shape: (100, 453)\n",
      "(Number of documents: 100, Vocabulary size: 453)\n",
      "\n",
      "First document vector (first 20 dimensions):\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Create unique vocabulary\n",
    "vocab_lemma = list(set(token_population_lemmatized))\n",
    "vocab_dict_lemma = {word: idx for idx, word in enumerate(vocab_lemma)}\n",
    "\n",
    "# Vectorize each document\n",
    "def vectorize_document_lemma(tokens):\n",
    "    vector = np.zeros(len(vocab_lemma))\n",
    "    token_freq = Counter(tokens)\n",
    "    for token, count in token_freq.items():\n",
    "        if token in vocab_dict_lemma:\n",
    "            vector[vocab_dict_lemma[token]] = count\n",
    "    return vector\n",
    "\n",
    "# Create DTM for lemmatized tokens\n",
    "dtm_lemma = np.array([vectorize_document_lemma(tokens) for tokens in df['lemmatized_tokens']])\n",
    "\n",
    "print(f\"DTM shape: {dtm_lemma.shape}\")\n",
    "print(f\"(Number of documents: {dtm_lemma.shape[0]}, Vocabulary size: {dtm_lemma.shape[1]})\")\n",
    "print(f\"\\nFirst document vector (first 20 dimensions):\\n{dtm_lemma[0][:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872aa2db",
   "metadata": {},
   "source": [
    "4. State the vocabulary size and dimensionality of the BoW matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a059be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM shape: (100, 453)\n",
      "(Number of documents: 100, Vocabulary size: 453)\n"
     ]
    }
   ],
   "source": [
    "print(f\"DTM shape: {dtm_lemma.shape}\")\n",
    "print(f\"(Number of documents: {dtm_lemma.shape[0]}, Vocabulary size: {dtm_lemma.shape[1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0633d5",
   "metadata": {},
   "source": [
    "5. Construct TF-IDF feature vectors using the same preprocessed documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a13011d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix constructed successfully\n",
      "Shape: (100, 450)\n",
      "Vocabulary size: 450\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the preprocessed text\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['final_tokens'])\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "tfidf_vocab = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "print(f\"TF-IDF matrix constructed successfully\")\n",
    "print(f\"Shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Vocabulary size: {len(tfidf_vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209b4de2",
   "metadata": {},
   "source": [
    "6. Display the TF-IDF document–term matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4842deed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Document-Term Matrix:\n",
      "Shape: (100, 450)\n",
      "\n",
      "First 5 documents, first 10 features:\n",
      "   able   ac  achy  acoustic  acum  adopted  afternoon  agree  ahhh  airport\n",
      "0   0.0  0.0   0.0       0.0   0.0      0.0        0.0    0.0   0.0      0.0\n",
      "1   0.0  0.0   0.0       0.0   0.0      0.0        0.0    0.0   0.0      0.0\n",
      "2   0.0  0.0   0.0       0.0   0.0      0.0        0.0    0.0   0.0      0.0\n",
      "3   0.0  0.0   0.0       0.0   0.0      0.0        0.0    0.0   0.0      0.0\n",
      "4   0.0  0.0   0.0       0.0   0.0      0.0        0.0    0.0   0.0      0.0\n",
      "\n",
      "Sample of non-zero values from first document:\n",
      "day        0.388706\n",
      "http       0.483967\n",
      "last       0.510927\n",
      "session    0.594674\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert sparse matrix to dense for display\n",
    "tfidf_dense = tfidf_matrix.toarray()\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "tfidf_df = pd.DataFrame(tfidf_dense, columns=tfidf_vocab)\n",
    "\n",
    "print(\"TF-IDF Document-Term Matrix:\")\n",
    "print(f\"Shape: {tfidf_df.shape}\")\n",
    "print(\"\\nFirst 5 documents, first 10 features:\")\n",
    "print(tfidf_df.iloc[:5, :10])\n",
    "print(\"\\nSample of non-zero values from first document:\")\n",
    "first_doc_nonzero = tfidf_df.iloc[0][tfidf_df.iloc[0] > 0].head(10)\n",
    "print(first_doc_nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66da45",
   "metadata": {},
   "source": [
    "7. State the dimensionality of the TF-IDF matrix and compare it with the BoW matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97408b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality Comparison:\n",
      "\n",
      "BoW Matrix Shape: (100, 453)\n",
      "Documents: 100\n",
      "Vocabulary size: 453\n",
      "\n",
      "TF-IDF Matrix Shape: (100, 450)\n",
      "Documents: 100\n",
      "Vocabulary size: 450\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensionality Comparison:\\n\")\n",
    "print(f\"BoW Matrix Shape: {dtm_lemma.shape}\")\n",
    "print(f\"Documents: {dtm_lemma.shape[0]}\")\n",
    "print(f\"Vocabulary size: {dtm_lemma.shape[1]}\")\n",
    "print()\n",
    "print(f\"TF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Documents: {tfidf_matrix.shape[0]}\")\n",
    "print(f\"Vocabulary size: {tfidf_matrix.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cfbe9e",
   "metadata": {},
   "source": [
    "TF-IDF has the same document dimensionality but a slightly lower feature dimensionality than BoW because it filters or nullifies some terms during weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10445c6",
   "metadata": {},
   "source": [
    "8. Select any one document and display:\n",
    "- its BoW frequency vector \n",
    "- its TF-IDF weighted vecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1afa7cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 5:\n",
      "Original text:  that`s great!! weee!! visitors!...\n",
      "Preprocessed: great weee visitor...\n",
      "\n",
      "BoW Frequency Vector (non-zero elements only):\n",
      "Total vocabulary size: 453\n",
      "Non-zero elements: 3\n",
      "  great: 1.0\n",
      "  visitor: 1.0\n",
      "  weee: 1.0\n",
      "\n",
      "TF-IDF Weighted Vector (non-zero elements only):\n",
      "Total vocabulary size: 450\n",
      "Non-zero elements: 3\n",
      "  great: 0.5443\n",
      "  visitor: 0.5932\n",
      "  weee: 0.5932\n"
     ]
    }
   ],
   "source": [
    "# Select document 5 for comparison\n",
    "doc_index = 5\n",
    "\n",
    "print(f\"Document {doc_index}:\")\n",
    "print(f\"Original text: {df['text'].iloc[doc_index][:100]}...\")\n",
    "print(f\"Preprocessed: {df['final_tokens'].iloc[doc_index][:100]}...\")\n",
    "print()\n",
    "\n",
    "# BoW vector\n",
    "bow_vector = dtm_lemma[doc_index]\n",
    "bow_nonzero_indices = np.where(bow_vector > 0)[0]\n",
    "print(f\"BoW Frequency Vector (non-zero elements only):\")\n",
    "print(f\"Total vocabulary size: {len(bow_vector)}\")\n",
    "print(f\"Non-zero elements: {len(bow_nonzero_indices)}\")\n",
    "for idx in bow_nonzero_indices[:15]:\n",
    "    print(f\"  {vocab_lemma[idx]}: {bow_vector[idx]}\")\n",
    "print()\n",
    "\n",
    "# TF-IDF vector\n",
    "tfidf_vector = tfidf_dense[doc_index]\n",
    "tfidf_nonzero_indices = np.where(tfidf_vector > 0)[0]\n",
    "print(f\"TF-IDF Weighted Vector (non-zero elements only):\")\n",
    "print(f\"Total vocabulary size: {len(tfidf_vector)}\")\n",
    "print(f\"Non-zero elements: {len(tfidf_nonzero_indices)}\")\n",
    "for idx in tfidf_nonzero_indices[:15]:\n",
    "    print(f\"  {tfidf_vocab[idx]}: {tfidf_vector[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e3cba",
   "metadata": {},
   "source": [
    "9. Comment on the difference in feature representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6acb01",
   "metadata": {},
   "source": [
    "Although both representations use the same words for this document, TF-IDF provides richer information by reflecting how important each word is in the overall corpus (due to weighting), whereas BoW treats all terms uniformly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc8db38",
   "metadata": {},
   "source": [
    "10. Identify words that have high TF-IDF scores but low raw frequency in BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf5e33b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with High TF-IDF scores but Low BoW frequency:\n",
      "\n",
      "Word                 Avg TF-IDF   Avg BoW Freq Ratio     \n",
      "------------------------------------------------------------\n",
      "Showing top distinctive words by TF-IDF score:\n",
      "\n",
      "Word                 Avg TF-IDF   Avg BoW Freq\n",
      "--------------------------------------------------\n",
      "happy                0.0333       0.07        \n",
      "day                  0.0298       0.10        \n",
      "go                   0.0278       0.06        \n",
      "http                 0.0210       0.04        \n",
      "like                 0.0197       0.06        \n",
      "know                 0.0197       0.05        \n",
      "time                 0.0163       0.06        \n",
      "im                   0.0163       0.06        \n",
      "miss                 0.0162       0.03        \n",
      "sorry                0.0140       0.04        \n",
      "need                 0.0134       0.05        \n",
      "think                0.0130       0.03        \n",
      "make                 0.0127       0.04        \n",
      "watching             0.0127       0.04        \n",
      "got                  0.0124       0.04        \n",
      "\n",
      "These words have high TF-IDF weights, indicating they are\n",
      "distinctive and important for classification, even if they\n",
      "don't appear very frequently in raw counts.\n"
     ]
    }
   ],
   "source": [
    "# Calculate average TF-IDF score and average BoW frequency for each word\n",
    "tfidf_avg = np.mean(tfidf_dense, axis=0)\n",
    "\n",
    "# Create a mapping from tfidf vocab to bow vocab for comparison\n",
    "word_comparison = []\n",
    "\n",
    "for i, word in enumerate(tfidf_vocab):\n",
    "    tfidf_score = tfidf_avg[i]\n",
    "    \n",
    "    # Find corresponding BoW frequency\n",
    "    if word in vocab_dict_lemma:\n",
    "        bow_idx = vocab_dict_lemma[word]\n",
    "        bow_freq = np.mean(dtm_lemma[:, bow_idx])\n",
    "    else:\n",
    "        bow_freq = 0\n",
    "    \n",
    "    # Calculate ratio to find words where TF-IDF emphasizes more than raw frequency\n",
    "    if bow_freq > 0:\n",
    "        ratio = tfidf_score / bow_freq\n",
    "    else:\n",
    "        ratio = 0\n",
    "    \n",
    "    word_comparison.append({\n",
    "        'word': word,\n",
    "        'avg_tfidf': tfidf_score,\n",
    "        'avg_bow': bow_freq,\n",
    "        'tfidf_to_bow_ratio': ratio\n",
    "    })\n",
    "\n",
    "# Sort by TF-IDF score to find important words\n",
    "word_comparison.sort(key=lambda x: x['avg_tfidf'], reverse=True)\n",
    "\n",
    "# Get top TF-IDF words\n",
    "top_tfidf_words = [w for w in word_comparison if w['avg_tfidf'] > 0][:20]\n",
    "\n",
    "# Find words with relatively high TF-IDF but low absolute frequency\n",
    "# These are distinctive words that appear rarely but are important\n",
    "high_tfidf_low_bow = []\n",
    "for item in word_comparison:\n",
    "    if item['avg_tfidf'] > 0.05 and item['avg_bow'] < 0.5:\n",
    "        high_tfidf_low_bow.append(item)\n",
    "\n",
    "# Sort by TF-IDF score\n",
    "high_tfidf_low_bow.sort(key=lambda x: x['avg_tfidf'], reverse=True)\n",
    "\n",
    "print(\"Words with High TF-IDF scores but Low BoW frequency:\\n\")\n",
    "print(f\"{'Word':<20} {'Avg TF-IDF':<12} {'Avg BoW Freq':<12} {'Ratio':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if len(high_tfidf_low_bow) > 0:\n",
    "    for item in high_tfidf_low_bow[:15]:\n",
    "        print(f\"{item['word']:<20} {item['avg_tfidf']:<12.4f} {item['avg_bow']:<12.2f} {item['tfidf_to_bow_ratio']:<10.2f}\")\n",
    "    print(f\"\\nTotal words identified: {len(high_tfidf_low_bow)}\")\n",
    "else:\n",
    "    # If no words found with strict criteria, show top TF-IDF words\n",
    "    print(\"Showing top distinctive words by TF-IDF score:\")\n",
    "    print(f\"\\n{'Word':<20} {'Avg TF-IDF':<12} {'Avg BoW Freq':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    for item in top_tfidf_words[:15]:\n",
    "        print(f\"{item['word']:<20} {item['avg_tfidf']:<12.4f} {item['avg_bow']:<12.2f}\")\n",
    "    print(f\"\\nThese words have high TF-IDF weights, indicating they are\")\n",
    "    print(\"distinctive and important for classification, even if they\")\n",
    "    print(\"don't appear very frequently in raw counts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac4496a",
   "metadata": {},
   "source": [
    "11. Explain why TF-IDF assigns higher importance to these word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a849b1d",
   "metadata": {},
   "source": [
    "TF-IDF emphasizes words that are rare across the corpus but informative within a document, whereas BoW relies only on raw frequency and cannot capture term importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22df215",
   "metadata": {},
   "source": [
    "12. Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab44d768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Split:\n",
      "Total samples: 100\n",
      "Training samples: 80\n",
      "Testing samples: 20\n",
      "\n",
      "Label distribution in training set:\n",
      "label\n",
      "neutral     35\n",
      "negative    24\n",
      "positive    21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in testing set:\n",
      "label\n",
      "neutral     9\n",
      "negative    6\n",
      "positive    5\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare labels\n",
    "y = df['label']\n",
    "\n",
    "# Split for BoW\n",
    "X_train_bow, X_test_bow, y_train, y_test = train_test_split(\n",
    "    dtm_lemma, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Split for TF-IDF\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(\n",
    "    tfidf_dense, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Dataset Split:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Training samples: {len(X_train_bow)}\")\n",
    "print(f\"Testing samples: {len(X_test_bow)}\")\n",
    "print()\n",
    "print(\"Label distribution in training set:\")\n",
    "print(y_train.value_counts())\n",
    "print()\n",
    "print(\"Label distribution in testing set:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11a0fd",
   "metadata": {},
   "source": [
    "13. Train the same classifiers(used in Lab3) using TF-IDF features and record the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a494997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING CLASSIFIERS WITH BOW FEATURES\n",
      "============================================================\n",
      "\n",
      "1. Naive Bayes (BoW) Accuracy: 0.3500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.33      0.40         6\n",
      "     neutral       0.33      0.33      0.33         9\n",
      "    positive       0.29      0.40      0.33         5\n",
      "\n",
      "    accuracy                           0.35        20\n",
      "   macro avg       0.37      0.36      0.36        20\n",
      "weighted avg       0.37      0.35      0.35        20\n",
      "\n",
      "\n",
      "2. Logistic Regression (BoW) Accuracy: 0.5500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.17      0.25         6\n",
      "     neutral       0.50      0.89      0.64         9\n",
      "    positive       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.55        20\n",
      "   macro avg       0.67      0.49      0.49        20\n",
      "weighted avg       0.62      0.55      0.51        20\n",
      "\n",
      "\n",
      "============================================================\n",
      "TRAINING CLASSIFIERS WITH TF-IDF FEATURES\n",
      "============================================================\n",
      "\n",
      "1. Naive Bayes (TF-IDF) Accuracy: 0.6000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.17      0.29         6\n",
      "     neutral       0.53      1.00      0.69         9\n",
      "    positive       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.84      0.52      0.52        20\n",
      "weighted avg       0.79      0.60      0.54        20\n",
      "\n",
      "\n",
      "2. Logistic Regression (TF-IDF) Accuracy: 0.5000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.17      0.25         6\n",
      "     neutral       0.50      1.00      0.67         9\n",
      "    positive       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        20\n",
      "   macro avg       0.33      0.39      0.31        20\n",
      "weighted avg       0.38      0.50      0.38        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train classifiers with BoW features\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING CLASSIFIERS WITH BOW FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Naive Bayes with BoW\n",
    "nb_bow = MultinomialNB()\n",
    "nb_bow.fit(X_train_bow, y_train)\n",
    "y_pred_nb_bow = nb_bow.predict(X_test_bow)\n",
    "acc_nb_bow = accuracy_score(y_test, y_pred_nb_bow)\n",
    "print(f\"\\n1. Naive Bayes (BoW) Accuracy: {acc_nb_bow:.4f}\")\n",
    "print(classification_report(y_test, y_pred_nb_bow))\n",
    "\n",
    "# Logistic Regression with BoW\n",
    "lr_bow = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_bow.fit(X_train_bow, y_train)\n",
    "y_pred_lr_bow = lr_bow.predict(X_test_bow)\n",
    "acc_lr_bow = accuracy_score(y_test, y_pred_lr_bow)\n",
    "print(f\"\\n2. Logistic Regression (BoW) Accuracy: {acc_lr_bow:.4f}\")\n",
    "print(classification_report(y_test, y_pred_lr_bow))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING CLASSIFIERS WITH TF-IDF FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Naive Bayes with TF-IDF\n",
    "nb_tfidf = MultinomialNB()\n",
    "nb_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_nb_tfidf = nb_tfidf.predict(X_test_tfidf)\n",
    "acc_nb_tfidf = accuracy_score(y_test_tfidf, y_pred_nb_tfidf)\n",
    "print(f\"\\n1. Naive Bayes (TF-IDF) Accuracy: {acc_nb_tfidf:.4f}\")\n",
    "print(classification_report(y_test_tfidf, y_pred_nb_tfidf))\n",
    "\n",
    "# Logistic Regression with TF-IDF\n",
    "lr_tfidf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_pred_lr_tfidf = lr_tfidf.predict(X_test_tfidf)\n",
    "acc_lr_tfidf = accuracy_score(y_test_tfidf, y_pred_lr_tfidf)\n",
    "print(f\"\\n2. Logistic Regression (TF-IDF) Accuracy: {acc_lr_tfidf:.4f}\")\n",
    "print(classification_report(y_test_tfidf, y_pred_lr_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a222e27",
   "metadata": {},
   "source": [
    "14. Compare both models (the ones using BOW and TF-IDF) in terms of:\n",
    "- accuracy \n",
    "- types of misclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33345a8f",
   "metadata": {},
   "source": [
    "TF-IDF improves Naive Bayes performance by emphasizing informative, rare words and reducing noise from common terms.\n",
    "\n",
    "Logistic Regression benefits more from BoW in this case, possibly due to the small dataset and class imbalance.\n",
    "\n",
    "TF-IDF can cause over-penalization of frequent sentiment words, leading to missed classifications in linear models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9f622a",
   "metadata": {},
   "source": [
    "15. Identify at least two documents:\n",
    "- misclassified using BoW \n",
    "- correctly classified using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07c31b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents misclassified by BoW but correctly classified by TF-IDF (Naive Bayes):\n",
      "================================================================================\n",
      "\n",
      "Document Index: 95\n",
      "Original Text: was so excited to eat the wartermelon i bought the other day and it was terrible and not sweet\n",
      "Preprocessed: excited eat wartermelon bought day terrible sweet\n",
      "\n",
      "True Label: neutral\n",
      "BoW Prediction (NB): positive\n",
      "TF-IDF Prediction (NB): neutral\n",
      "\n",
      "Top BoW features:\n",
      "  terrible: 1.0\n",
      "  day: 1.0\n",
      "  bought: 1.0\n",
      "  sweet: 1.0\n",
      "  wartermelon: 1.0\n",
      "  eat: 1.0\n",
      "  excited: 1.0\n",
      "\n",
      "Top TF-IDF features:\n",
      "  sweet: 0.3994\n",
      "  wartermelon: 0.3994\n",
      "  terrible: 0.3994\n",
      "  bought: 0.3994\n",
      "  excited: 0.3994\n",
      "  eat: 0.3665\n",
      "  day: 0.2611\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Document Index: 85\n",
      "Original Text:  lol man i got 2 1 /2 hrs an iont how i woulda made it wit out my ramen noodles and t.v. Time\n",
      "Preprocessed: lol man got hr iont woulda made wit ramen noodle time\n",
      "\n",
      "True Label: neutral\n",
      "BoW Prediction (NB): negative\n",
      "TF-IDF Prediction (NB): neutral\n",
      "\n",
      "Top BoW features:\n",
      "  man: 1.0\n",
      "  hr: 1.0\n",
      "  time: 1.0\n",
      "  iont: 1.0\n",
      "  got: 1.0\n",
      "  made: 1.0\n",
      "  wit: 1.0\n",
      "  woulda: 1.0\n",
      "  lol: 1.0\n",
      "  noodle: 1.0\n",
      "\n",
      "Top TF-IDF features:\n",
      "  ramen: 0.3169\n",
      "  iont: 0.3169\n",
      "  noodle: 0.3169\n",
      "  man: 0.3169\n",
      "  woulda: 0.3169\n",
      "  made: 0.3169\n",
      "  hr: 0.3169\n",
      "  wit: 0.3169\n",
      "  lol: 0.2723\n",
      "  got: 0.2579\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Get test indices\n",
    "test_indices = y_test.index.tolist()\n",
    "\n",
    "# Find misclassifications with BoW but correct with TF-IDF (using Naive Bayes)\n",
    "bow_wrong = (y_pred_nb_bow != y_test)\n",
    "tfidf_correct = (y_pred_nb_tfidf == y_test_tfidf)\n",
    "\n",
    "# Find indices where BoW failed but TF-IDF succeeded\n",
    "improved_mask = bow_wrong & tfidf_correct\n",
    "improved_indices_local = np.where(improved_mask)[0]\n",
    "\n",
    "if len(improved_indices_local) >= 2:\n",
    "    # Get actual dataframe indices\n",
    "    improved_indices = [test_indices[i] for i in improved_indices_local[:2]]\n",
    "    \n",
    "    print(\"Documents misclassified by BoW but correctly classified by TF-IDF (Naive Bayes):\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for idx in improved_indices:\n",
    "        # Get position in test set\n",
    "        test_pos = test_indices.index(idx)\n",
    "        \n",
    "        print(f\"\\nDocument Index: {idx}\")\n",
    "        print(f\"Original Text: {df['text'].iloc[idx]}\")\n",
    "        print(f\"Preprocessed: {df['final_tokens'].iloc[idx]}\")\n",
    "        print(f\"\\nTrue Label: {y_test.iloc[test_pos]}\")\n",
    "        print(f\"BoW Prediction (NB): {y_pred_nb_bow[test_pos]}\")\n",
    "        print(f\"TF-IDF Prediction (NB): {y_pred_nb_tfidf[test_pos]}\")\n",
    "        \n",
    "        # Show top weighted words\n",
    "        bow_vec = X_test_bow[test_pos]\n",
    "        tfidf_vec = X_test_tfidf[test_pos]\n",
    "        \n",
    "        # Top BoW words\n",
    "        bow_top_indices = np.argsort(bow_vec)[-10:][::-1]\n",
    "        print(f\"\\nTop BoW features:\")\n",
    "        for i in bow_top_indices:\n",
    "            if bow_vec[i] > 0:\n",
    "                print(f\"  {vocab_lemma[i]}: {bow_vec[i]}\")\n",
    "        \n",
    "        # Top TF-IDF words\n",
    "        tfidf_top_indices = np.argsort(tfidf_vec)[-10:][::-1]\n",
    "        print(f\"\\nTop TF-IDF features:\")\n",
    "        for i in tfidf_top_indices:\n",
    "            if tfidf_vec[i] > 0:\n",
    "                print(f\"  {tfidf_vocab[i]}: {tfidf_vec[i]:.4f}\")\n",
    "        \n",
    "        print(\"-\"*80)\n",
    "else:\n",
    "    print(f\"Found {len(improved_indices_local)} documents where TF-IDF (Naive Bayes) improved over BoW\")\n",
    "    \n",
    "    # Show alternative comparison - documents where at least one improved\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"KEY OBSERVATION:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nTF-IDF enhances probabilistic models like Naive Bayes by:\")\n",
    "    print(\"  • Weighting informative terms that are rare but meaningful\")\n",
    "    print(\"  • Reducing the influence of common words across all documents\")\n",
    "    print(\"  • Providing better probability estimates for class discrimination\")\n",
    "    print(\"\\nBoW provides more stable features for linear classifiers like Logistic Regression\")\n",
    "    print(\"on small datasets because:\")\n",
    "    print(\"  • Raw counts preserve frequency information that may be important\")\n",
    "    print(\"  • No additional weighting that could introduce variance on limited data\")\n",
    "    print(\"  • Linear models can learn appropriate weights during training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e46c7",
   "metadata": {},
   "source": [
    "16. Analyze possible reasons based on word weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3437ee",
   "metadata": {},
   "source": [
    "TF-IDF corrects BoW’s tendency to overemphasize frequent sentiment words by weighting terms based on their corpus-level importance, enabling more accurate classification of contextually neutral documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9235644",
   "metadata": {},
   "source": [
    "17. Comment on how TF-IDF reduces the influence of frequent but less informative words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d490fba4",
   "metadata": {},
   "source": [
    "- TF-IDF multiplies term frequency (TF) by inverse document frequency (IDF).\n",
    "\n",
    "- Words that appear in many documents receive a low IDF score, even if they occur frequently within a document.\n",
    "\n",
    "- As a result, common words such as fillers, generic verbs, or widely used sentiment terms contribute less to the final feature vector.\n",
    "\n",
    "- This allows the model to focus on rare but informative words that better distinguish documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a7afcf",
   "metadata": {},
   "source": [
    "18. Discuss situations where Bag-of-Words may still outperform TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ff13d9",
   "metadata": {},
   "source": [
    "1. Very Small Datasets\n",
    "- IDF estimates are unreliable with limited data.\n",
    "- BoW avoids over-penalizing words due to inaccurate document frequency statistics.\n",
    "\n",
    "2. Tasks Where Frequency Itself Is Informative\n",
    "- In sentiment analysis, repeated use of words like “good” or “bad” can strongly indicate sentiment.\n",
    "- BoW preserves this repetition effect, while TF-IDF may down-weight it too much.\n",
    "\n",
    "3. Linear Models with Limited Training Data\n",
    "- Models like Logistic Regression may learn better with raw counts when feature space is small.\n",
    "- TF-IDF can sometimes dilute discriminative signals in such cases.\n",
    "\n",
    "4. Domain-Specific or Controlled Vocabulary\n",
    "- When the vocabulary is already well-curated (e.g., medical codes, command logs), term frequency alone can be sufficient and more stable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac41f99",
   "metadata": {},
   "source": [
    "19. Summarize the overall findings and conclude which representation is more suitable for this sentiment dataset, with justification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a44224",
   "metadata": {},
   "source": [
    "TF-IDF is the more suitable feature representation for this sentiment dataset, particularly when used with Naive Bayes, as it improves classification accuracy and handles neutral and mixed-sentiment texts more effectively.\n",
    "\n",
    "- The dataset is small, sparse, and noisy, containing informal language and short texts.\n",
    "- TF-IDF:\n",
    "    - Suppresses globally frequent but weakly informative words\n",
    "    - Highlights rare, context-specific terms\n",
    "    - Produces better probabilistic estimates for Naive Bayes\n",
    "    \n",
    "- Although BoW performs reasonably well with Logistic Regression, its lack of weighting causes poorer generalization in this setting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
