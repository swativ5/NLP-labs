{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "821ddedf",
   "metadata": {},
   "source": [
    "A1. Data Loading\n",
    "Load the dataset into a Pandas DataFrame. Extract the text column and treat each entry as a separate document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1177db7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 100 documents\n",
      "Columns: ['text', 'label']\n",
      "\n",
      "First few rows:\n",
      "                                                text     label\n",
      "0  Last session of the day  http://twitpic.com/67ezh   neutral\n",
      "1   Shanghai is also really exciting (precisely -...  positive\n",
      "2  Recession hit Veronique Branquinho, she has to...  negative\n",
      "3                                        happy bday!  positive\n",
      "4             http://twitpic.com/4w75p - I like it!!  positive\n",
      "\n",
      "Dataset after removing links: 96 documents\n",
      "                                                text     label\n",
      "1   Shanghai is also really exciting (precisely -...  positive\n",
      "2  Recession hit Veronique Branquinho, she has to...  negative\n",
      "3                                        happy bday!  positive\n",
      "5                    that`s great!! weee!! visitors!  positive\n",
      "6            I THINK EVERYONE HATES ME ON HERE   lol  negative\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('test.csv', encoding='latin1')\n",
    "\n",
    "# Keep only text and sentiment columns\n",
    "df = df.drop(columns=[col for col in df.columns if col not in ['text', 'sentiment']])\n",
    "\n",
    "# Clean the data\n",
    "df = df.dropna()\n",
    "df = df.drop(df.index[100:])  # Keep first 100 rows\n",
    "df = df.rename(columns={'sentiment': 'label'})\n",
    "\n",
    "print(f\"Dataset loaded: {len(df)} documents\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Remove all rows with links in it\n",
    "df = df[~df['text'].str.contains('http')]\n",
    "print(f\"\\nDataset after removing links: {len(df)} documents\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a91b09",
   "metadata": {},
   "source": [
    "A2. Tokenization\n",
    "Tokenize all documents and store the tokens corresponding to each document using NLTK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eee309dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization completed for 96 documents\n",
      "\n",
      "Example - First document:\n",
      "Original text:  Shanghai is also really exciting (precisely -- skyscrapers galore). Good tweeps in China:  (SH)  (BJ).\n",
      "Tokens: ['shanghai', 'is', 'also', 'really', 'exciting', '(', 'precisely', '--', 'skyscrapers', 'galore', ')', '.', 'good', 'tweeps', 'in', 'china', ':', '(', 'sh', ')', '(', 'bj', ')', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "\n",
    "def swati_tokenise(text):\n",
    "    tokens = [word.lower() for word in text.split()]\n",
    "\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['text'].apply(lambda x: word_tokenize(str(x).lower()))\n",
    "\n",
    "# Custom for funsies\n",
    "# df['tokens'] = df['text'].apply(lambda x: swati_tokenise(str(x).lower()))\n",
    "\n",
    "print(f\"Tokenization completed for {len(df)} documents\")\n",
    "print(\"\\nExample - First document:\")\n",
    "print(f\"Original text: {df['text'].iloc[0]}\")\n",
    "print(f\"Tokens: {df['tokens'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b10fe8",
   "metadata": {},
   "source": [
    "A3. Token Population\n",
    "Merge the tokens obtained from all documents and create a master list of distinct tokens present across the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808a2ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens (with repetitions): 1390\n",
      "Unique tokens in population: 585\n",
      "\n",
      "Sample tokens: ['anything', 'come', '...', 'oscillate', 'huh', 'marley', 'peoples', 'bought', 'airport', 'later', 'faux', 'system', 'about', 'stupid', 'appearances', 'well', 'spend', 'storm', '(', 'is']\n"
     ]
    }
   ],
   "source": [
    "# Create token population - distinct tokens across all documents\n",
    "all_tokens = []\n",
    "for tokens in df['tokens']:\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "# Get unique tokens\n",
    "token_population = list(set(all_tokens))\n",
    "\n",
    "print(f\"Total tokens (with repetitions): {len(all_tokens)}\")\n",
    "print(f\"Unique tokens in population: {len(token_population)}\")\n",
    "print(f\"\\nSample tokens: {token_population[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d65812",
   "metadata": {},
   "source": [
    "A4. Stop-words\n",
    "Study the concept of stop-words and identify why they are removed in text analysis. Load and examine the English stop-words list using NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efb45350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop-words: 198\n",
      "\n",
      "Sample stop-words: ['more', \"i'm\", 'i', 'herself', 'does', 'few', 'd', \"i'll\", 'again', 'weren', 'own', 'being', \"won't\", 'over', 'she', 'after', 'both', \"haven't\", 'between', 'theirs', 'them', 'ourselves', 'was', 'about', 'each', 'itself', 'll', 'needn', \"aren't\", 'been']\n",
      "\n",
      "--- Analysis of Stop-words ---\n",
      "Stop-words are commonly occurring words like 'the', 'is', 'at', 'which', 'on', etc.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "# Load English stop-words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "print(f\"Number of stop-words: {len(stop_words)}\")\n",
    "print(f\"\\nSample stop-words: {list(stop_words)[:30]}\")\n",
    "print(\"\\n--- Analysis of Stop-words ---\")\n",
    "print(\"Stop-words are commonly occurring words like 'the', 'is', 'at', 'which', 'on', etc.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229090a3",
   "metadata": {},
   "source": [
    "- These are stop words because they are very common function words (pronouns, auxiliaries, prepositions, and contractions) that add grammatical structure but little semantic meaning.\n",
    "- They occur frequently across texts and do not help distinguish topics or content.\n",
    "- Removing them reduces noise and improves efficiency in most NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9799542",
   "metadata": {},
   "source": [
    "A5. Bag-of-Words Construction\n",
    "Remove stop-words from the token population and construct a Bag-of-Words with unique, meaningful tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "942c4a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token population before filtering: 585\n",
      "Bag-of-Words size (after removing stop-words): 455\n",
      "\n",
      "Sample BoW tokens: ['able', 'ac', 'achy', 'acoustic', 'acum', 'adopted', 'afternoon', 'agree', 'ahhh', 'airport', 'almost', 'alone', 'alright', 'also', 'always', 'anime', 'another', 'answer', 'antibacterial', 'anything', 'appearances', 'apple', 'argh', 'armpit', 'around', 'ask', 'attention', 'bad', 'bank', 'bday']\n"
     ]
    }
   ],
   "source": [
    "# Remove stop-words and non-alphabetic tokens from token population\n",
    "bag_of_words = [token for token in token_population \n",
    "                if token not in stop_words and token.isalpha()]\n",
    "\n",
    "# Sort for consistency\n",
    "bag_of_words = sorted(bag_of_words)\n",
    "\n",
    "print(f\"Token population before filtering: {len(token_population)}\")\n",
    "print(f\"Bag-of-Words size (after removing stop-words): {len(bag_of_words)}\")\n",
    "print(f\"\\nSample BoW tokens: {bag_of_words[:30]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c5947a",
   "metadata": {},
   "source": [
    "A6. Document Vectorization\n",
    "Create a Bag-of-Words feature vector for each document. Each dimension represents a word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87a9c57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document vectors shape: (96, 455)\n",
      "(Number of documents: 96, Vocabulary size: 455)\n",
      "\n",
      "First document vector (first 20 dimensions): [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = {word: idx for idx, word in enumerate(bag_of_words)}\n",
    "\n",
    "# Vectorize each document\n",
    "def vectorize_document(tokens):\n",
    "    filtered_tokens = [token for token in tokens \n",
    "                      if token not in stop_words and token.isalpha()]\n",
    "    \n",
    "    # Count occurrences\n",
    "    token_counts = Counter(filtered_tokens)\n",
    "    \n",
    "    # Create vector\n",
    "    vector = np.zeros(len(bag_of_words))\n",
    "    for token, count in token_counts.items():\n",
    "        if token in vocab:\n",
    "            vector[vocab[token]] = count\n",
    "    \n",
    "    return vector\n",
    "\n",
    "# Apply vectorization to all documents\n",
    "document_vectors = np.array([vectorize_document(tokens) for tokens in df['tokens']])\n",
    "\n",
    "print(f\"Document vectors shape: {document_vectors.shape}\")\n",
    "print(f\"(Number of documents: {document_vectors.shape[0]}, Vocabulary size: {document_vectors.shape[1]})\")\n",
    "print(f\"\\nFirst document vector (first 20 dimensions): {document_vectors[0][:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ffc62",
   "metadata": {},
   "source": [
    "A7. Dataset Preparation for Classification\n",
    "Combine the document vectors with their sentiment labels and split into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75ed85a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 67 documents\n",
      "Testing set: 29 documents\n",
      "\n",
      "Label distribution in training set:\n",
      "neutral     30\n",
      "negative    20\n",
      "positive    17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution in testing set:\n",
      "neutral     13\n",
      "negative     9\n",
      "positive     7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = document_vectors\n",
    "y = df['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} documents\")\n",
    "print(f\"Testing set: {X_test.shape[0]} documents\")\n",
    "print(f\"\\nLabel distribution in training set:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "print(f\"\\nLabel distribution in testing set:\")\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db73e72",
   "metadata": {},
   "source": [
    "A8. Sentiment Classification\n",
    "Train a machine learning classifier using the Bag-of-Words vectors and predict sentiment labels for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3cef1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for both classifiers!\n",
      "\n",
      "Naive Bayes predictions: ['neutral' 'negative' 'positive' 'negative' 'neutral' 'positive' 'neutral'\n",
      " 'negative' 'positive' 'neutral']\n",
      "Logistic Regression predictions: ['neutral' 'negative' 'positive' 'neutral' 'neutral' 'neutral' 'neutral'\n",
      " 'neutral' 'positive' 'neutral']\n",
      "Actual labels: ['negative' 'positive' 'positive' 'neutral' 'negative' 'positive'\n",
      " 'neutral' 'negative' 'positive' 'negative']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "y_pred_nb = nb_classifier.predict(X_test)\n",
    "\n",
    "lr_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_classifier.fit(X_train, y_train)\n",
    "y_pred_lr = lr_classifier.predict(X_test)\n",
    "\n",
    "print(\"Training completed for both classifiers!\")\n",
    "print(f\"\\nNaive Bayes predictions: {y_pred_nb[:10]}\")\n",
    "print(f\"Logistic Regression predictions: {y_pred_lr[:10]}\")\n",
    "print(f\"Actual labels: {y_test[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921bffb",
   "metadata": {},
   "source": [
    "A9. Model Evaluation\n",
    "\n",
    "Evaluate the performance of the classifiers using metrics such as accuracy, precision, recall, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba1b1b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NAIVE BAYES CLASSIFIER RESULTS\n",
      "============================================================\n",
      "Accuracy:  0.4483\n",
      "Precision: 0.4574\n",
      "Recall:    0.4483\n",
      "F1-Score:  0.4473\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3 3 3]\n",
      " [4 6 3]\n",
      " [1 2 4]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.38      0.33      0.35         9\n",
      "     neutral       0.55      0.46      0.50        13\n",
      "    positive       0.40      0.57      0.47         7\n",
      "\n",
      "    accuracy                           0.45        29\n",
      "   macro avg       0.44      0.46      0.44        29\n",
      "weighted avg       0.46      0.45      0.45        29\n",
      "\n",
      "\n",
      "============================================================\n",
      "LOGISTIC REGRESSION CLASSIFIER RESULTS\n",
      "============================================================\n",
      "Accuracy:  0.5517\n",
      "Precision: 0.5589\n",
      "Recall:    0.5517\n",
      "F1-Score:  0.4680\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1  7  1]\n",
      " [ 0 13  0]\n",
      " [ 1  4  2]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.11      0.18         9\n",
      "     neutral       0.54      1.00      0.70        13\n",
      "    positive       0.67      0.29      0.40         7\n",
      "\n",
      "    accuracy                           0.55        29\n",
      "   macro avg       0.57      0.47      0.43        29\n",
      "weighted avg       0.56      0.55      0.47        29\n",
      "\n",
      "\n",
      "============================================================\n",
      "COMPARISON & ANALYSIS\n",
      "============================================================\n",
      "Naive Bayes Accuracy:       44.83%\n",
      "Logistic Regression Accuracy: 55.17%\n",
      "\n",
      "Performance Difference:     10.34%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"NAIVE BAYES CLASSIFIER RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate metrics for Naive Bayes\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "nb_precision = precision_score(y_test, y_pred_nb, average='weighted', zero_division=0)\n",
    "nb_recall = recall_score(y_test, y_pred_nb, average='weighted', zero_division=0)\n",
    "nb_f1 = f1_score(y_test, y_pred_nb, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Accuracy:  {nb_accuracy:.4f}\")\n",
    "print(f\"Precision: {nb_precision:.4f}\")\n",
    "print(f\"Recall:    {nb_recall:.4f}\")\n",
    "print(f\"F1-Score:  {nb_f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_nb, zero_division=0))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOGISTIC REGRESSION CLASSIFIER RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate metrics for Logistic Regression\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lr)\n",
    "lr_precision = precision_score(y_test, y_pred_lr, average='weighted', zero_division=0)\n",
    "lr_recall = recall_score(y_test, y_pred_lr, average='weighted', zero_division=0)\n",
    "lr_f1 = f1_score(y_test, y_pred_lr, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Accuracy:  {lr_accuracy:.4f}\")\n",
    "print(f\"Precision: {lr_precision:.4f}\")\n",
    "print(f\"Recall:    {lr_recall:.4f}\")\n",
    "print(f\"F1-Score:  {lr_f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr, zero_division=0))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON & ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Naive Bayes Accuracy:       {nb_accuracy:.2%}\")\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy:.2%}\")\n",
    "print(f\"\\nPerformance Difference:     {abs(lr_accuracy - nb_accuracy):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33585d",
   "metadata": {},
   "source": [
    "- Logistic Regression (55.17%) outperformed Naive Bayes (44.83%) by 10.3%\n",
    "- LR heavily biases toward predicting \"neutral\" class (13/13 neutral samples correctly identified, but over-predicts it)\n",
    "- The model struggles with negative sentiment (only 11% recall) and positive sentiment (29% recall)\n",
    "- Small dataset size (29 test samples) and class imbalance are major limiting factors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
